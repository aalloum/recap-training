# Guide Complet Kafka Streams - Questions & R√©ponses

## Table des mati√®res

- [Concepts Fondamentaux](#concepts-fondamentaux)
- [Structures de Donn√©es](#structures-de-donn√©es)
- [Gestion d'√âtat](#gestion-d√©tat)
- [Tol√©rance aux Pannes](#tol√©rance-aux-pannes)
- [Fen√™trage et Temps](#fen√™trage-et-temps)
- [Joins et Repartitionnement](#joins-et-repartitionnement)
- [Questions Avanc√©es](#questions-avanc√©es)
- [Design et Production](#design-et-production)

---

## Concepts Fondamentaux

### Qu'est-ce que Kafka Streams exactement ?

**Q:** Pourriez-vous expliquer ce qu'est Kafka Streams et comment il s'int√®gre dans l'√©cosyst√®me Kafka ?

**A:** Kafka Streams est une librairie Java permettant de cr√©er des applications de stream processing stateful directement au-dessus de Kafka. Contrairement √† un framework distribu√© traditionnel, ce n'est pas un cluster s√©par√© : c'est une application Java classique qui lit depuis Kafka, traite les donn√©es en temps r√©el et √©crit les r√©sultats dans Kafka.

**Avantages cl√©s :**
- Exactly-once semantics nativement support√©
- √âtat local avec r√©plication via changelog topics
- D√©ploiement simple (aucun cluster √† g√©rer)
- Haute disponibilit√© et tol√©rance aux pannes

---

### Kafka Streams est-il une librairie ou un framework ?

**Q:** Quelle est la distinction entre Kafka Streams et un vrai framework de streaming ?

**A:** Kafka Streams est une **librairie**, pas un framework. Il n'y a pas de cluster s√©par√©, pas de master, pas de worker. C'est simplement une d√©pendance Java que vous embarquez dans votre application. Cela contraste avec des solutions comme Apache Flink qui sont des frameworks distribu√©s complets.

---

### Comment Kafka Streams se compare-t-il aux Consumer/Producer bas niveau ?

**Q:** Quelle est la diff√©rence entre utiliser directement les APIs Consumer/Producer et Kafka Streams ?

**A:** 

| Aspect | Consumer/Producer | Kafka Streams |
|--------|------------------|---------------|
| Niveau d'abstraction | Bas niveau | Haut niveau |
| Gestion d'√©tat | Aucune par d√©faut | Stateful nativement |
| Offsets et state | Gestion manuelle | Automatique |
| DSL disponible | Non | Oui (Topology DSL + Processor API) |

Kafka Streams encapsule les Consumer/Producer tout en ajoutant une couche de gestion d'√©tat, de windowing et d'agr√©gations automatiques.

---

## Structures de Donn√©es

### Quelle est la diff√©rence entre KStream et KTable ?

**Q:** Quand devriez-vous utiliser un KStream plut√¥t qu'une KTable ?

**A:** 

**KStream** repr√©sente un flux d'√©v√©nements infini o√π chaque message est trait√© ind√©pendamment :
- Chaque nouveau message = nouvel √©v√©nement
- Pas de suppression, pas de mise √† jour
- Exemple : logs, transactions, clickstreams

**KTable** repr√©sente une vue de l'√©tat courant, o√π la cl√© mappe √† la derni√®re valeur :
- Mise √† jour remplace l'√©tat pr√©c√©dent
- Comportement similaire √† une table SQL
- Exemple : profil utilisateur, taux de change actuel

**Analogie :** KTable = changelog d'une table, KStream = journal infini.

---

### Qu'est-ce qu'une GlobalKTable et quand l'utiliser ?

**Q:** Comment fonctionne une GlobalKTable et en quoi diff√®re-t-elle d'une KTable ordinaire ?

**A:** Une GlobalKTable est une KTable enti√®rement r√©pliqu√©e sur chaque instance Kafka Streams, contrairement √† une KTable partitionn√©e.

**Cas d'utilisation id√©aux :**
- Petites tables de r√©f√©rence (pays, taux, configurations)
- Joins sans repartitionnement co√ªteux
- Cl√© de lookup diff√©rente de la cl√© Kafka

**Avantages :**
- Pas de repartitionnement obligatoire
- Lookup local tr√®s rapide
- Pas de shuffle Kafka

**√Ä √©viter si :**
- Table volumineuse
- Mises √† jour tr√®s fr√©quentes
- M√©moire disponible limit√©e

---

## Gestion d'√âtat

### Qu'est-ce qu'un state store et comment fonctionne-t-il ?

**Q:** Comment Kafka Streams g√®re-t-il l'√©tat persistant ?

**A:** Un state store est un stockage local utilis√© par Kafka Streams pour maintenir l'√©tat entre les traitements. Il permet les op√©rations comme :
- Agr√©gations (count, sum, etc.)
- Joins entre streams
- Windowing

**Types de state stores :**
- **RocksDB** (persistant, par d√©faut) : stockage disk-based tr√®s performant
- **In-memory** (volatil, rare en production)

**Caract√©ristiques essentielles :**
- Chaque store est sauvegard√© dans un changelog topic Kafka
- En cas de crash, l'√©tat est reconstruit automatiquement depuis Kafka
- Kafka reste la source de v√©rit√©, le disque local est un cache

---

### Comment Kafka Streams nettoie-t-il automatiquement le state store ?

**Q:** Sans utiliser le windowing, le state store est-il jamais supprim√© automatiquement ?

**A:** **Non.** Sans windowing, Kafka Streams conserve l'√©tat ind√©finiment. Le state :
- Grandit ind√©finiment
- Reste en m√©moire/disque
- N'est jamais supprim√© automatiquement

C'est dangereux quand la cardinalit√© des cl√©s est non born√©e (userId, sessionId infinis).

**Solutions pour impl√©menter une dur√©e de vie (TTL) :**

1. **Windowing** (meilleure pratique)
   ```
   TimeWindows.ofSizeWithGrace(
       Duration.ofMinutes(10),
       Duration.ofMinutes(2)
   )
   ```
   Kafka supprime automatiquement l'√©tat apr√®s window_end + grace.

2. **Retention sur le state store**
   ```
   Materialized.as("store")
     .withRetention(Duration.ofHours(1))
   ```

3. **Suppression manuelle via Processor API**
   - Stocker un timestamp
   - Utiliser punctuate() pour nettoyer r√©guli√®rement

4. **Tombstones (KTable uniquement)**
   - Envoyer une valeur null supprime la cl√©

---

### Que signifie TTL en streaming ?

**Q:** Comment impl√©mentez-vous une dur√©e de vie limite pour les donn√©es ?

**A:** **TTL** (Time To Live) est la dur√©e maximale pendant laquelle une donn√©e reste valide. Pass√© ce d√©lai, elle doit √™tre supprim√©e.

**En Kafka Streams, le TTL s'impl√©mente principalement via le windowing :**

```
TimeWindows.ofSizeWithGrace(
    Duration.ofMinutes(10),   ‚Üê dur√©e de la fen√™tre (TTL principal)
    Duration.ofMinutes(2)     ‚Üê d√©lai accepted pour retards
)
```

Les donn√©es sont supprim√©es apr√®s : 10 min + 2 min = 12 minutes.

**Pourquoi c'est critique :**
- Sans TTL : state store grandit ind√©finiment ‚ùå
- Avec TTL : state store reste ma√Ætris√© ‚úÖ
- Rebalances plus rapides
- Co√ªts r√©duits

---

### O√π RocksDB stocke-t-il le state store ?

**Q:** Comment r√©cup√©rer l'√©tat Kafka Streams en cas de besoin ?

**A:** RocksDB stocke le state store sur le disque local de l'instance :

```
/tmp/kafka-streams/<application.id>/
‚îú‚îÄ‚îÄ 0_0/              (task)
‚îÇ   ‚îú‚îÄ‚îÄ rocksdb/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orders-store/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ checkpoint
‚îú‚îÄ‚îÄ 0_1/
‚îî‚îÄ‚îÄ global/           (GlobalKTable)
```

**Points critiques :**

- Chaque task a son propre dossier et RocksDB isol√©
- **Kafka reste la source de v√©rit√©**, pas le disque
- En cas de crash, l'√©tat est reconstruit depuis le changelog topic
- Pour modifier le chemin :
  ```
  state.dir=/var/lib/kafka-streams
  ```

**En production :**
- Utiliser un disque SSD rapide
- Assez d'espace disponible
- Volume persistant en Kubernetes

---

## Tol√©rance aux Pannes

### Comment Kafka Streams garantit-il la tol√©rance aux pannes ?

**Q:** Que se passe-t-il quand une instance Kafka Streams tombe ?

**A:** Kafka Streams utilise une architecture r√©siliente bas√©e sur Kafka :

**M√©canisme de r√©cup√©ration :**
1. Crash d'une instance
2. Rebalance automatique du consumer group
3. Redistribution des tasks aux instances restantes
4. Restauration de l'√©tat depuis les changelog topics
5. Reprise du traitement

**√âl√©ments cl√©s :**
- **Changelog topics** : chaque state store a un topic Kafka associ√©
- **Exactly-once semantics** : transactions Kafka garantissent pas de doublon
- **Standby replicas** : copies passives du state pour red√©marrage rapide

**R√©sultat :** Transparence totale pour l'utilisateur.

---

### Qu'est-ce que Exactly Once Semantics (EOS) ?

**Q:** Comment Kafka Streams assure-t-il qu'aucun message n'est trait√© deux fois ?

**A:** Exactly-once Semantics (EOS) garantit que :
- Aucun message n'est perdu
- Aucun message n'est trait√© deux fois
- Les r√©sultats sont idempotents

**Impl√©mentation technique :**
- Transactions Kafka
- Producers idempotents
- Commit atomique d'offsets + output

**Configuration :**
```
processing.guarantee=exactly_once_v2
```

**Comparaison avec at-least-once :**

| S√©mantique | Garantie | Perfs | Complexit√© |
|-----------|----------|-------|-----------|
| At-least-once | Messages dupliqu√©s possibles | ‚ö° Rapide | ‚úÖ Simple |
| Exactly-once | Aucun doublon | üê¢ Plus lent | ‚ùå Complexe |

At-least-once est plus rapide mais demande une logique idempotente c√¥t√© m√©tier.

---

### Diff√©rence entre standby replicas et state store actif

**Q:** √Ä quoi servent les standby replicas et quand les configurer ?

**A:** 

**State store actif :**
- Utilis√© pour le traitement r√©el
- Produit les r√©sultats
- Assign√© √† une task active

**Standby replica :**
- Copie passive synchronis√©e
- Lit le changelog topic
- Ne traite aucun record
- Devient actif en cas de panne

**Avantages des standby replicas :**
- Red√©marrage plus rapide (√©tat d√©j√† local)
- Moins de reprocessing du changelog
- Meilleure disponibilit√©

**Configuration :**
```
num.standby.replicas=1
```

**Important :** Une standby replica ne peut pas traiter les partitions. Elle ne fait que synchroniser l'√©tat.

---

## Fen√™trage et Temps

### Comment fonctionne le windowing dans Kafka Streams ?

**Q:** Pourquoi avez-vous besoin de fen√™trer vos donn√©es en streaming ?

**A:** Le windowing d√©coupe un flux infini en intervalles de temps pour permettre l'agr√©gation. Sans windowing, vous ne pouvez pas agr√©ger "pour toujours".

**Types de fen√™tres :**

**1. Tumbling (fixe, non chevauchant)**
```
|----5min----|----5min----|----5min----|
```
- Fen√™tres ind√©pendantes
- Pas de chevauchement
- Performance optimale
- Cas : m√©triques par minute

**2. Hopping (fixe, chevauchant)**
```
|----5min----|
     |----5min----|
```
- Fen√™tres qui se chevauchent
- Recalcul plus fr√©quent
- Co√ªt en √©tat plus √©lev√©

**3. Sliding (bas√© sur la distance)**
- Comparaison √©v√©nement-√†-√©v√©nement
- Pas align√© sur l'horloge
- Cas : d√©tection de fraude

**4. Session (bas√© sur l'inactivit√©)**
- Fen√™tres dynamiques
- Se fusionnent automatiquement
- Cas : sessions utilisateur

---

### Qu'est-ce que le grace period ?

**Q:** Comment g√©rez-vous les √©v√©nements qui arrivent en retard ?

**A:** Le grace period d√©finit combien de temps Kafka Streams accepte les √©v√©nements arrivant apr√®s la fermeture th√©orique d'une fen√™tre.

```
TimeWindows.ofSizeAndGrace(
    Duration.ofMinutes(5),    ‚Üê taille de fen√™tre
    Duration.ofMinutes(2)     ‚Üê grace period
)
```

**Comportement :**
- Fen√™tre : 0-5 min
- Grace : jusqu'√† 7 min (5 + 2)
- Apr√®s 7 min : √©v√©nements rejet√©s

**Sans grace period :**
- √âv√©nements rejet√©s imm√©diatement apr√®s fermeture
- Perte de data valide

**Avec grace period :**
- Tol√©rance aux retards r√©seau
- Recalcul des agr√©gations
- Impact sur le state store (gard√© plus longtemps)

---

### Event time vs Processing time

**Q:** Quelle est la diff√©rence entre le timestamp du message et le moment du traitement ?

**A:** 

**Event time :**
- Timestamp du message Kafka (quand l'√©v√©nement s'est r√©ellement produit)
- D√©fini par le producteur ou un TimestampExtractor
- Pr√©f√©r√© par Kafka Streams

**Processing time :**
- Moment exact o√π l'application traite le message
- Variable (latence r√©seau, retards)
- Non recommand√© pour les agr√©gations

**Pourquoi Kafka Streams pr√©f√®re event time :**
- G√®re les retards et le d√©sordre
- Idempotent (m√™me resultat quel que soit quand on reprocess)
- Compatible avec reprocessing

---

## Joins et Repartitionnement

### Pourquoi le repartitionnement est-il co√ªteux ?

**Q:** Comment minimiser les repartitionnements dans votre topologie ?

**A:** Un repartitionnement est d√©clench√© quand Kafka Streams doit reshuffle les donn√©es :
- `groupBy()` change la cl√©
- Un join sur cl√©s diff√©rentes
- Agr√©gations non-keyed

**Co√ªt du repartitionnement :**
- I/O r√©seau vers Kafka
- Latence accrue
- Stockage Kafka suppl√©mentaire
- Changelog topic cr√©√© automatiquement

**Solutions pour l'√©viter :**

**1. Bien choisir la cl√© d√®s la production (MEILLEURE SOLUTION)**
- Design le contrat d√®s le d√©part
- Cl√© Kafka = cl√© de jointure
- √âvite selectKey() plus tard

**2. Utiliser groupByKey() plut√¥t que groupBy()**
```
stream.groupByKey()  // pas de changement, pas de repartition
```

**3. Utiliser GlobalKTable pour les petites tables**
- Pas de repartition
- Lookup local

**4. Pr√©-partitionner les topics**
- M√™me nombre de partitions
- M√™me strat√©gie de hashing
- M√™me cl√© de partition

**5. Accepter le repartition si n√©cessaire**
- Mais en le contr√¥lant :
  - Nombre de partitions
  - R√©tention
  - Compaction

---

### Diff√©rence entre un join KStream-KTable et KStream-KStream

**Q:** Quel type de join choisir selon vos donn√©es ?

**A:** 

**KStream-KTable (inner join)**
```
Stream d'√©v√©nements + Table d'√©tat
= Enrichissement d'√©v√©nements
```
- L'√©v√©nement est enrichi avec la valeur courante de la table
- Pas de windowing requis
- Cas : enrichir les clics avec le profil utilisateur

**KStream-KStream (join)**
```
Deux streams d'√©v√©nements
= Corr√©lation temporelle
```
- N√©cessite une fen√™tre (window)
- √âv√©nements proche dans le temps sont join√©s
- Cas : d√©tecter les paires achat-retour

**KTable-KTable (join)**
```
Deux tables d'√©tat
= Jointure statique
```
- Pas de windowing
- Mises √† jour d√©clenchent le rejoin
- Cas : produit + cat√©gorie

---

### Combien de partitions un task peut-il traiter ?

**Q:** Comment sont assign√©es les partitions aux tasks ?

**A:** Un task Kafka Streams peut traiter plusieurs partitions. L'assignation d√©pend de la topologie.

**R√®gle cl√© :**
> Le nombre de tasks est d√©termin√© par le nombre maximal de partitions parmi les topics source co-partitionn√©s.

**Exemple :**
```
Topic A : 6 partitions
Topic B : 6 partitions
Join A-B (co-partitionn√©)

R√©sultat : 6 tasks
Task-0 : A-0 + B-0
Task-1 : A-1 + B-1
...
Task-5 : A-5 + B-5
```

**Cardinalit√© :**
- Une instance = plusieurs stream threads
- Un thread = traite UNE task √† la fois
- Une task = peut avoir plusieurs partitions assign√©es

---

## Questions Avanc√©es

### Qu'est-ce que le changelog topic ?

**Q:** Comment Kafka Streams persiste-t-il l'√©tat localement ?

**A:** Un changelog topic est un topic Kafka interne associ√© √† chaque state store. Il enregistre chaque modification d'√©tat :

**M√©canisme :**
1. Modification du state store local
2. √âcriture atomique dans le changelog topic
3. Kafka devient la source de v√©rit√©

**Avantages :**
- Tol√©rance aux pannes (reconstruction depuis Kafka)
- Rebalancing sans perte d'√©tat
- Kafka = backup automatique
- Compaction possible

**Exemple :**
```
State store "orders" ‚Üí Topic "_orders-stream-orders-changelog"
```

**En cas de crash :**
1. Instance red√©marre
2. Rejoue le changelog topic
3. Reconstruit l'√©tat exactement
4. Reprend le traitement

---

### Pourquoi Kafka Streams utilise-t-il RocksDB ?

**Q:** Quels sont les avantages de RocksDB par rapport aux alternatives ?

**A:** 

**RocksDB :**
- Stockage disk-based performant
- Tr√®s rapide pour les op√©rations key-value
- G√®re de gros volumes d'√©tat
- Int√©gr√© nativement dans Kafka Streams
- **Choix par d√©faut en production**

**Alternative : In-Memory**
- Plus rapide
- Mais volatil (perte en crash)
- Rarement utilis√© en production
- D√©ploiement sur une seule instance uniquement

**RocksDB par d√©faut car :**
- Robustesse
- Performance acceptable
- Scalabilit√© (disque > RAM)
- Durabilit√©

---

### Comment g√©rer les erreurs de d√©s√©rialisation ?

**Q:** Que faire quand un message ne peut pas √™tre pars√© ?

**A:** Kafka Streams permet de g√©rer les erreurs de mani√®re granulaire :

**Handlers disponibles :**

1. **DeserializationExceptionHandler**
   - G√®re les erreurs de parsing
   - Options : skip ou fail

2. **ProductionExceptionHandler**
   - G√®re les erreurs lors de l'√©criture
   - Options : continue ou fail

3. **Dead Letter Topic**
   - Rediriger les messages probl√©matiques
   - Topic s√©par√© pour analyse

**Approche recommand√©e :**
```
Essayer ‚Üí En cas d'erreur ‚Üí Rediriger vers dead-letter
```

**Importance :**
- √âvite que 1 message corrompu arr√™te le pipeline
- Tra√ßabilit√© des erreurs
- Retraitement manuel possible

---

### Comment s√©curiser une application Kafka Streams ?

**Q:** Quels m√©canismes de s√©curit√© impl√©menter en production ?

**A:** 

**Authentification et Chiffrement :**
- SSL/TLS pour les communications Kafka
- SASL pour l'authentification (SASL/PLAIN, SASL/SCRAM)

**Autorisation :**
- ACLs Kafka (Access Control Lists)
- Contr√¥le granulaire par topic

**Donn√©es sensibles :**
- Encryption at rest
- Stockage des secrets via Vault ou Kubernetes

**Best practices :**
- Secrets en environnement, pas en code
- Certificats valides et renouvel√©s
- Audit logging
- Monitoring des acc√®s

---

## Design et Production

### Quand NE PAS utiliser Kafka Streams ?

**Q:** Quels cas d'usage ne conviennent pas √† Kafka Streams ?

**A:** 

**Kafka Streams n'est pas adapt√© si :**

1. **Tr√®s gros batchs historiques**
   - Kafka Streams = streaming, pas batch
   - Pr√©f√©rer : Spark, Flink

2. **Streaming SQL pur**
   - Utiliser : ksqlDB
   - Kafka Streams = code Java

3. **Besoin multi-langage**
   - Kafka Streams = Java/Scala uniquement
   - Pr√©f√©rer : Flink, Spark

4. **DAGs tr√®s complexes**
   - Kafka Streams = topologies simples/mod√©r√©es
   - Pr√©f√©rer : Flink

5. **State distribu√© requis**
   - Kafka Streams = state local
   - Pr√©f√©rer : Flink avec state distribu√©

---

### Comment migrer une application Kafka Streams sans downtime ?

**Q:** Comment passer √† une nouvelle version de topologie ?

**A:** 

**Strat√©gie recommand√©e : Nouveau consumer group (GOLD STANDARD)**

```
App v1 (application.id = orders-stream-v1)
    ‚Üì
Deploy App v2 (application.id = orders-stream-v2)
    ‚Üì
Reprocess depuis le d√©but ou offset sp√©cifique
    ‚Üì
Double √©criture temporaire (v1 et v2)
    ‚Üì
V√©rification des r√©sultats
    ‚Üì
Switch downstream vers v2
    ‚Üì
Retrait de v1
```

**Avantages :**
- ‚úÖ Zero downtime
- ‚úÖ Rollback facile
- ‚úÖ Test en parall√®le

**Inconv√©nients :**
- ‚ùå Double co√ªt temporaire
- ‚ùå Double trafic

**Alternative : Versionnement des topics**
```
output-v1 ‚Üí output-v2
```
- Switch consumer downstream
- Rollback facile

**√Ä √âVITER absolument :**
- ‚ùå Modifier la topologie avec le m√™me application.id
- ‚ùå Toucher aux state stores manuellement

---

### Comment versionner une topologie Kafka Streams ?

**Q:** Quel est l'impact d'une modification de topologie ?

**A:** Une topologie Kafka Streams est **immuable**. Tout changement significatif n√©cessite une nouvelle version.

**Ce qui change = nouvelle topologie :**
- Logique de processing
- Joins
- Fen√™tres
- State stores

**Comment versionner :**

**1. Application ID versionn√©e**
```
application.id = "orders-stream-v2"
```

**2. Noms de state stores versionn√©s**
```
Materialized.as("orders-store-v2")
```

**3. Topics de sortie versionn√©s**
```
output-v1 ‚Üí output-v2
```

**4. Changelog topics**
- Cr√©√©s automatiquement
- Li√©s au state store

**Strat√©gie de rollback :**
- Garder v1 et v2 en parall√®le
- Switcher le traffic progressivement

---

### Comment g√©rer un state store √©norme ?

**Q:** Que faire quand le state store devient trop volumineux ?

**A:** 

**Probl√®mes d'un state store √©norme :**
- Temps de restore tr√®s longs
- Disque local satur√©
- Rebalances lentes
- Startup lent apr√®s crash

**Solutions avanc√©es :**

**1. R√©duire la taille du state**
- TTL (Time To Live) sur les donn√©es
- Windows avec grace period court
- Suppression proactive des donn√©es obsol√®tes

**2. Utiliser des standby replicas**
```
num.standby.replicas=1
```
- Restore plus rapide
- Moins de replay du changelog
- Disponibilit√© am√©lior√©e

**3. Augmenter le parall√©lisme**
- Plus de partitions
- State plus petit par task
- Meilleure scalabilit√©

**4. Compression et compaction**
- Changelog compact√©
- R√©duction de la taille Kafka

**5. Externaliser (si n√©cessaire)**
- Redis, Cassandra
- ‚ö†Ô∏è Perte possible d'exactly-once

**Approche recommand√©e :**
```
TTL + Standby replicas + Augmentation du parall√©lisme
```

---

### Comment tester Kafka Streams ?

**Q:** Comment valider votre logique sans d√©ployer en production ?

**A:** 

**Tests unitaires :**
- **TopologyTestDriver** : test sans Kafka
- Mock des state stores
- Assertions simples

**Tests d'int√©gration :**
- **Testcontainers** : Kafka en Docker
- Topologie r√©elle
- Sc√©narios complexes

**Approche recommand√©e :**
1. Tests unitaires avec TopologyTestDriver (rapides)
2. Tests d'int√©gration avec Testcontainers (complets)
3. D√©ploiement canary en production

---

### Diff√©rence entre DSL et Processor API

**Q:** Quand utiliser le Processor API plut√¥t que la DSL ?

**A:** 

| Aspect | DSL | Processor API |
|--------|-----|---------------|
| Niveau | Haut niveau | Bas niveau |
| Facilit√© | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Facile | ‚≠ê‚≠ê Complexe |
| Paradigme | D√©claratif | Imp√©ratif |
| Contr√¥le | Standard | Total |

**DSL (Recommended)** :
```java
stream.groupByKey()
      .windowedBy(TimeWindows.ofSize(...))
      .count()
```
- Lisible
- Performant
- Peu de code

**Processor API** :
```java
topology.addProcessor("custom", CustomProcessor::new, ...)
```
- Flexible
- Custom logic
- State contr√¥l√©

**Utiliser Processor API si :**
- Logique tr√®s complexe
- Custom state management
- Custom punctuation
- Optimisations bas-niveau

---

### Qu'est-ce que Punctuation ?

**Q:** Comment ex√©cuter du code √† intervalle r√©gulier ?

**A:** Punctuation est un m√©canisme pour ex√©cuter du code p√©riodiquement dans un Processor :

**Types :**
- **Event time** : bas√© sur le timestamp des messages
- **Wall-clock time** : horloge syst√®me

**Cas d'usage :**
- Nettoyage de state
- Flush manuel
- Ex√©cution p√©riodique

**Exemple :**
```java
context.schedule(
  Duration.ofMinutes(5),
  PunctuationType.WALL_CLOCK_TIME,
  timestamp -> {
    // Ex√©cut√© chaque 5 minutes
    cleanupExpiredEntries();
  }
);
```

---

### Combien de fois une standby replica peut traiter ?

**Q:** Est-ce qu'une standby replica traite des partitions ?

**A:** **Non, jamais.** Une standby replica ne traite aucun record.

**R√¥le d'une standby replica :**
- Synchronisation passive du state
- Lecture du changelog topic
- Pr√©paration √† devenir active

**Quand elle devient active :**
- Lors d'un crash d'une instance
- Lors d'un rebalance
- Lors d'un scaling

**Pourquoi ne pas traiter ?**
- ‚ùå Double processing = violation exactly-once
- ‚ùå Incoh√©rence de state
- ‚ùå R√©sultats dupliqu√©s

**Note sp√©ciale : GlobalKTable**
- Pas de standby replicas
- Chaque instance a une copie active
- Charg√©e par un global thread

---

### GlobalKTable n√©cessite-t-elle une co-partition ?

**Q:** Pourquoi GlobalKTable n'a pas besoin d'√™tre co-partitionn√©e ?

**A:** Parce que **chaque instance poss√®de une copie compl√®te** de la GlobalKTable.

**Contrairement √† KTable :**
- KTable est partitionn√©e
- Chaque partition sur une instance diff√©rente
- Join n√©cessite co-partition

**GlobalKTable :**
- R√©pliqu√©e enti√®rement sur chaque instance
- Join = lookup local en m√©moire/RocksDB
- **Pas de shuffle Kafka**

**Illustration :**
```
KTable (partitionn√©e) :
Partition 0 ‚Üí Instance A
Partition 1 ‚Üí Instance B

GlobalKTable (r√©pliqu√©e) :
Instance A : [Partition 0, 1, 2, ...]
Instance B : [Partition 0, 1, 2, ...]
Instance C : [Partition 0, 1, 2, ...]
```

**Cl√© diff√©rente :**
```java
stream.join(
  globalTable,
  (streamKey, streamValue) -> streamValue.getCountryCode(),
  joiner
)
```
- Lookup par cl√© diff√©rente de la cl√© Kafka
- Pas de repartitionnement

**Trade-offs :**

| Avantage | Inconv√©nient |
|----------|-------------|
| Pas de repartition | Consomme m√©moire/disque |
| Latence basse | Scale pas bien |
| Simple | Table volumineuse = risqu√© |

---

### Comment impl√©menter un compteur temps r√©el avec expiration ?

**Q:** Design : compteur utilisateur par minute avec TTL ?

**A:** 

**Approche :**

```java
stream
  .groupByKey()
  .windowedBy(
    TimeWindows.ofSizeWithGrace(
      Duration.ofMinutes(1),   // fen√™tre = 1 min
      Duration.ofSeconds(10)   // accepter 10s de retard
    )
  )
  .count()
  .toStream()
  .to("counts-output");
```

**√âl√©ments :**
1. **KStream** : flux des √©v√©nements utilisateur
2. **groupByKey()** : regrouper par cl√© (userId)
3. **windowedBy()** : cr√©er des fen√™tres de 1 min
4. **count()** : compter
5. **Grace period** : 10s pour accepter les retards

**O√π c'est stock√© :**
- State store local (RocksDB)
- Changelog topic pour r√©plication
- TTL = window size + grace = 1 min 10s

**Apr√®s 1 min 10s :**
- Fen√™tre ferm√©e
- √âtat supprim√© automatiquement
- Partition √©crite dans output topic

---

### Comment g√©rer le schema evolution ?

**Q:** Comment g√©rer les changements de sch√©ma en production ?

**A:** 

**Outil recommand√© :**
- **Avro** ou **Protobuf** + Schema Registry

**Modes de compatibilit√© :**
- **Backward** : nouveaux consumers lisent vieilles donn√©es
- **Forward** : vieux consumers lisent nouvelles donn√©es
- **Full** : les deux

**Attention aux state stores :**
- Changement de sch√©ma = reprocessing possible
- State incompatible = corruption
- Version du state = nouveau application.id

**Approche :**
1. Nouvelle version du sch√©ma
2. V√©rifier compatibilit√©
3. D√©ployer avec nouveau application.id si break
4. Reprocess du d√©but

---

### Comment monitorer Kafka Streams ?

**Q:** Quelles m√©triques surveiller ?

**A:** 

**M√©triques disponibles :**
- **JMX Metrics** : d√©taill√©es
- **Lag par consumer group** : retard de traitement
- **State store size** : croissance de l'√©tat
- **Throughput / Latency** : performance

**Outils de monitoring :**
- Prometheus + Grafana
- Confluent Control Center
- Datadog, New Relic

**Metriques cl√©s √† alerter :**
- Lag trop √©lev√© (retard)
- State store d√©passe limite
- Rebalances fr√©quentes
- Erreurs de processing

---

## Questions Suppl√©mentaires Avanc√©es

### Comment fonctionne exactement le repartition topic en interne ?

**Q:** Quelles sont les √©tapes exactes lors d'un repartitionnement ?

**A:** Le repartitionnement intervient quand une op√©ration change la cl√©. Voici le processus :

**√âtapes :**
1. Kafka Streams d√©tecte un changement de cl√© (`groupBy`, `selectKey`, etc.)
2. Un repartition topic est cr√©√© automatiquement
3. Les messages sont recl√©s (r√©partitionn√©s par nouvelle cl√©)
4. Les partitions sont redistribu√©es
5. Un changelog topic est associ√© au repartition topic

**Exemple concret :**
```java
stream
  .selectKey((k, v) -> v.getCountryCode())  // Change la cl√© !
  .groupByKey()
  .count()
```

**Co√ªts associ√©s :**
- √âcriture r√©seau vers Kafka
- Lecture depuis le repartition topic
- Latence accrue
- I/O suppl√©mentaire

**Comment le reconna√Ætre :**
- Topics Kafka avec pattern : `<app-id>-TOPIC-repartition`
- Augmentation du lag
- Surcharge I/O

---

### Quelle est la diff√©rence entre StreamsBuilder et Topology ?

**Q:** √Ä quel niveau de la hi√©rarchie Kafka Streams travaille-t-on ?

**A:** 

**StreamsBuilder :**
- API DSL haut niveau et facile
- M√©thode fluente pour construire la topologie
- Recommand√©e pour 95% des cas

```java
StreamsBuilder builder = new StreamsBuilder();
builder.stream("input")
       .filter(...)
       .to("output");
```

**Topology :**
- Repr√©sentation interne bas niveau
- G√©n√©r√©e automatiquement par StreamsBuilder
- Peut √™tre manipul√©e directement si besoin
- Moins intuitive

**Relation :**
```
StreamsBuilder.build() ‚Üí Topology
                       ‚Üì
                 KafkaStreams(topology)
```

**En production :**
- Kafka Streams ex√©cute une Topology
- StreamsBuilder = API de d√©veloppement
- Vous interagissez avec StreamsBuilder, Kafka Streams g√®re la Topology

---

### Comment fonctionne le task model de Kafka Streams ?

**Q:** Comment le parall√©lisme est-il impl√©ment√© ?

**A:** Le task model est la base du parall√©lisme dans Kafka Streams.

**D√©finition :**
- Une **task** = un sous-ensemble de partitions d'un topic
- Une task est trait√©e par **un et un seul thread**
- Une task = unit√© d'isolation et d'√©tat

**Composition d'une task :**
- Partitions assign√©es (ex: partition 0, 1, 2)
- State stores propres
- Changelog topics associ√©s
- Offsets commit√©s

**Parall√©lisme :**
```
Partitions disponibles = limite maximale de tasks
Tasks = limite du parall√©lisme possible

Exemple :
Topic : 12 partitions
‚Üí Maximum 12 tasks en parall√®le
‚Üí Scaling max = 12 instances
```

**Cardinalit√© :**
```
1 instance = plusieurs threads
1 thread = traite 1 task √† la fois
1 task = peut avoir plusieurs partitions
```

**Cas : 6 partitions, 4 threads :**
```
Thread 1 : Task-0 (partitions 0, 3)
Thread 2 : Task-1 (partitions 1, 4)
Thread 3 : Task-2 (partitions 2, 5)
Thread 4 : (idle)
```

---

### Qu'est-ce que Topology.describe() et pourquoi l'utiliser ?

**Q:** Comment visualiser la structure de votre topologie ?

**A:** `Topology.describe()` fournit une repr√©sentation textuelle de votre topologie, tr√®s utile pour d√©boguer.

**Utilit√© :**
- V√©rifier la structure cr√©√©e
- Valider les connexions
- Trouver les erreurs de design
- Documenter

**Exemple de sortie :**
```
Sub-topologies:
Sub-topology: 0
  Source: KSTREAM-SOURCE-0000000000 (topics: [orders])
    ‚Üí Processor: KSTREAM-MAPVALUES-0000000001
      ‚Üí Processor: KSTREAM-FILTER-0000000002
        ‚Üí Sink: KSTREAM-SINK-0000000003 (topic: filtered-orders)
```

**√Ä toujours utiliser :**
```java
Topology topology = builder.build();
System.out.println(topology.describe());
```

**Vous verrez :**
- Sources (topics consomm√©s)
- Processors (op√©rations)
- Sinks (topics √©crits)
- Repartition topics
- State stores

---

### Comment g√©rer les keyed vs non-keyed streams ?

**Q:** Quelle est l'importance de la cl√© en Kafka Streams ?

**A:** 

**Non-keyed stream :**
- Pas de cl√© (null ou ignor√©e)
- Chaque message = individuel
- Pas de joins possibles
- Pas d'√©tat par cl√©

```java
stream.filter(...).map(...)  // cl√© ignor√©e
```

**Keyed stream :**
- Message = (cl√©, valeur)
- Cl√© d√©termine la partition
- Joins par cl√©
- √âtat par cl√©

```java
stream.groupByKey()  // regroupe par cl√©
      .count()       // state par cl√©
```

**Impact critique :**
```
KStream non-keyed ‚Üí count() ‚Üí erreur !
KStream keyed ‚Üí count() ‚Üí OK
```

**Comment fixer une cl√© :**
```java
stream.selectKey((k, v) -> v.getUserId())
      .groupByKey()
      .count()
```

**Consid√©rations :**
- Cl√© = partitionnement
- Cl√© = co-location des donn√©es
- Cl√© bien choisie = performance
- Cl√© mal choisie = repartition co√ªteux

---

### Comment Kafka Streams g√®re-t-il le rebalance en d√©tail ?

**Q:** Que se passe-t-il exactement lors d'un rebalance ?

**A:** Le rebalance est un processus complexe et critique pour la disponibilit√©.

**D√©clencheurs du rebalance :**
- Nouvelle instance lanc√©e
- Instance crash√©e (timeout d√©tect√©)
- Consumer quitte le groupe
- R√©√©quilibrage du nombre d'instances

**√âtapes du rebalance :**

1. **Pause du traitement**
   - Tous les threads s'arr√™tent
   - √âtat sauvegard√©

2. **R√©vocation des tasks**
   ```
   onPartitionsRevoked()
   ```
   - Flush de l'√©tat
   - Commit des offsets

3. **R√©assignation des partitions**
   - Calcul de la nouvelle distribution
   - Assigner les tasks aux instances

4. **R√©tablissement des tasks**
   ```
   onPartitionsAssigned()
   ```
   - Restauration de l'√©tat depuis Kafka
   - Rattrapage du lag

5. **Reprise du traitement**
   - Normale imm√©diatement

**Dur√©e typique :**
- Quelques secondes √† minutes (selon taille state store)

**Optimisations :**

**Cooperative rebalancing :**
```
processing.guarantee=exactly_once_v2
```
- Rebalance partiel
- R√©duit le stop-the-world
- Plus rapide

**Standby replicas :**
```
num.standby.replicas=1
```
- Pr√©pare la restauration
- Rebalance plus rapide

**Impact :**
- Pendant rebalance = z√©ro traitement
- State √† restaurer = latence
- Coordination complexe

---

### Comment Kafka Streams g√®re le scaling ?

**Q:** Comment ajouter ou retirer des instances ?

**A:** 

**Scaling horizontal (ajouter des instances) :**

Avant :
```
3 instances
12 partitions
‚Üí 4 partitions par instance
```

Apr√®s ajout instance 4 :
```
4 instances
12 partitions
‚Üí 3 partitions par instance
‚Üí Rebalance automatique
```

**Kafka Streams fait automatiquement :**
1. D√©tecte la nouvelle instance
2. Rebalance les tasks
3. Redistribue les partitions
4. Restaure l'√©tat

**Scaling limit√© par :**
- Nombre de partitions (max N instances pour N partitions)
- Nombre de cl√©s (pour non-windowed)
- Ressources CPU/RAM par instance

**Cas limite :**
```
10 partitions
100 instances
‚Üí 90 instances idle (sans work)
‚Üí Co√ªteux !
```

**Solution : Augmenter les partitions**
```
10 partitions ‚Üí 100 partitions
+ Reprocessing du changelog
+ Temps initial
```

**Best practice :**
- Partir avec 2x le nombre d'instances pr√©vu
- Augmenter les partitions avant les instances
- Monitorer le lag pendant rebalance

---

### Qu'est-ce que le cache dans Kafka Streams ?

**Q:** √Ä quoi sert `cache.max.bytes.buffering` ?

**A:** Le cache buff√®rise les modifications avant de les √©crire au state store et Kafka.

**Comportement :**
```
Update ‚Üí Cache (en m√©moire)
         ‚Üì (quand plein)
      State store (RocksDB)
         ‚Üì (async)
      Kafka (changelog)
```

**Configuration :**
```
cache.max.bytes.buffering=10485760  (10 MB par d√©faut)
```

**Impact :**

**Plus de cache :**
- ‚úÖ Meilleures performances (moins d'I/O)
- ‚ùå Plus de latence (avant flush)
- ‚ùå Plus de m√©moire

**Moins de cache :**
- ‚úÖ Basse latence
- ‚ùå Plus d'I/O
- ‚ùå Overhead I/O

**Relation avec commit.interval.ms :**
```
commit.interval.ms=30000  (30 secondes)
```
- Frequency de flush du cache
- Ind√©pendant de la taille du cache

**Cas d'usage :**
```
High-throughput streaming
‚Üí Gros cache + long commit interval
‚Üí Performance

Low-latency streaming
‚Üí Petit cache + court commit interval
‚Üí R√©activit√©
```

---

### Comment utiliser TopologyTestDriver ?

**Q:** Comment tester Kafka Streams sans Kafka r√©el ?

**A:** TopologyTestDriver permet de tester des topologies de mani√®re unitaire et rapide.

**Setup :**
```java
TopologyTestDriver testDriver = new TopologyTestDriver(
    builder.build(),
    new Properties()  // StreamsConfig
);

TestInputTopic<String, String> inputTopic =
    testDriver.createInputTopic("input", 
                               new StringSerializer(), 
                               new StringSerializer());

TestOutputTopic<String, Long> outputTopic =
    testDriver.createOutputTopic("output",
                                new StringDeserializer(),
                                new LongDeserializer());
```

**Test :**
```java
inputTopic.pipeInput("user1", "event");
inputTopic.pipeInput("user2", "event");

KeyValue<String, Long> output = outputTopic.readKeyValue();
assertEquals("user1", output.key);
assertEquals(1L, output.value);
```

**Avantages :**
- ‚úÖ Pas de Kafka requis
- ‚úÖ Tr√®s rapide
- ‚úÖ Id√©al pour CI/CD
- ‚úÖ Facile √† d√©boguer

**Limitations :**
- ‚ùå Pas de rebalance test√©
- ‚ùå Pas de multi-instance
- ‚ùå √âtat en-m√©moire uniquement

**Bonne pratique :**
```
Tests unitaires : TopologyTestDriver
Tests d'int√©gration : Testcontainers (Kafka r√©el)
Tests canary : Production avec faible traffic
```

---

### Comment impl√©menter un dead letter topic ?

**Q:** O√π envoyer les messages non traitables ?

**A:** Un dead letter topic (DLT) capture les messages qui ne peuvent pas √™tre trait√©s.

**Cas d'usage :**
- Erreurs de d√©s√©rialisation
- Validation √©chou√©e
- Exception non g√©r√©e

**Impl√©mentation simple :**
```java
KStream<String, String> stream = builder.stream("input");

stream
  .filter((k, v) -> {
    try {
      validateMessage(v);
      return true;
    } catch (Exception e) {
      // Envoyer au DLT
      return false;
    }
  })
  .to("output");
```

**Meilleure approche (avec d√©tail d'erreur) :**
```java
stream
  .flatMap((k, v) -> {
    try {
      List<KeyValue<String, String>> result = new ArrayList<>();
      result.add(new KeyValue<>(k, processMessage(v)));
      return result;
    } catch (Exception e) {
      // Wrapper avec erreur
      String errorPayload = createErrorPayload(v, e);
      List<KeyValue<String, String>> errors = new ArrayList<>();
      errors.add(new KeyValue<>(k, errorPayload));
      return errors;
    }
  })
  .to("output");  // Ou rediriger vers DLT
```

**Pattern recommand√© :**
```
Input Stream
    ‚îú‚îÄ‚îÄ Valid ‚Üí Output Topic
    ‚îú‚îÄ‚îÄ Invalid (parse error) ‚Üí DLT
    ‚îî‚îÄ‚îÄ Validation failed ‚Üí DLT
```

**Traitement du DLT :**
- Monitoring / Alerting
- Retraitement manuel
- Analyse des erreurs
- Feedback sur la qualit√© data

---

### Comment Kafka Streams cr√©e-t-il les topics internes ?

**Q:** Quels topics Kafka Streams cr√©e automatiquement ?

**A:** Kafka Streams cr√©e plusieurs topics automatiquement pour son fonctionnement.

**Topics cr√©√©s :**

**1. Changelog topics**
```
<application-id>-<store-name>-changelog
```
- Un par state store
- Compact√©
- Stocke toutes les modifications

**2. Repartition topics**
```
<application-id>-<topic-name>-repartition
```
- Cr√©√© si changement de cl√©
- Stockage temporaire
- Suppression possible apr√®s compaction

**3. Topics de sortie**
```
user-defined (vous les cr√©ez)
```

**Configuration :**
```
topic.cleanup.policy=compact  (changelog)
topic.cleanup.policy=delete   (repartition)
```

**Nommage et ordre :**
```
Materialized.as("store-name")
‚Üí Topic: <app-id>-store-name-changelog
```

**Impact :**
- Chaque state store = un topic suppl√©mentaire
- Cr√©e une complexit√© visuelle dans Kafka
- √Ä monitorer

---

### Comment g√©rer les large state stores ?

**Q:** Quand externaliser l'√©tat hors de Kafka ?

**A:** Parfois, le state store devient trop gros pour RocksDB local.

**Sympt√¥mes :**
- Temps de restore > 10 minutes
- Disque satur√©
- Rebalances tr√®s lents
- Startup lents apr√®s crash

**Options :**

**1. Externaliser vers Redis**
```
Avantages : rapide, scalable
Inconv√©nients : perte EOS, latence r√©seau
```

**2. Externaliser vers Cassandra**
```
Avantages : scalable, durable
Inconv√©nients : complexit√©, co√ªts
```

**3. Snapshot + S3**
```
Avantages : backup, versioning
Inconv√©nients : latence au restore
```

**‚ö†Ô∏è Trade-offs critiques :**
```
RocksDB local : EOS ‚úÖ, state local ‚úÖ, scalabilit√© ‚ùå
Redis externe : EOS ‚ùå, latence ‚ùå, scalabilit√© ‚úÖ
```

**Recommandation :**
```
Avant d'externaliser :
1. R√©duire la dur√©e de vie (TTL)
2. Augmenter les partitions
3. Utiliser standby replicas
4. Optimiser le state store

Si vraiment n√©cessaire :
‚Üí Externaliser + Processor API custom
‚Üí Mais perdre EOS
```

---

### Qu'est-ce que le stream-time et le watermark ?

**Q:** Comment Kafka Streams g√®re le temps en streaming ?

**A:** Kafka Streams maintient un stream-time interne pour coordonner les fen√™tres.

**Stream-time :**
- Timestamp maximum vu jusqu'√† pr√©sent
- Avance avec les √©v√©nements
- D√©termine la fermeture des fen√™tres

**Watermark (implicite) :**
- Contrairement √† Flink, **pas de watermark explicite**
- Mais comportement similaire
- Stream-time = watermark implicite

**M√©canisme :**
```
Message avec timestamp T
‚Üí stream-time = max(stream-time, T)
‚Üí Fen√™tres avec stream-time < T ferm√©es
‚Üí √âtat supprim√©
```

**Fermeture de fen√™tre :**
```
window_end + grace_period < stream-time
‚Üí fen√™tre ferm√©e
‚Üí r√©sultat final √©mis
‚Üí state supprim√©
```

**Impact sur le processing :**
- Event time = source de v√©rit√©
- Processeurs ne voient pas stream-time directement
- Contr√¥l√© via event-time des messages

---

### Comment g√©rer le consumer lag en Kafka Streams ?

**Q:** Comment monitorer et r√©duire le lag ?

**A:** Le lag indique le retard par rapport au dernier message du topic.

**D√©finition :**
```
Lag = Latest Offset - Current Offset
```

**Causes d'un lag √©lev√© :**
1. Processing lent (logique complexe)
2. State restore long (new instance)
3. Rebalance fr√©quents
4. Erreurs de processing

**Monitoring :**
```
M√©triques JMX :
- kafka.streams.record-lag
- kafka.streams.record-lag-max
```

**Outils :**
- Burrow (LinkedIn)
- Confluent Control Center
- Prometheus exporters

**Comment r√©duire le lag :**

1. **Optimiser la logique**
   - √âviter op√©rations co√ªteuses
   - Filtrer t√¥t

2. **Augmenter le parall√©lisme**
   - Plus de partitions
   - Plus d'instances

3. **Optimiser le state store**
   - R√©duire la taille
   - Utiliser standby replicas

4. **Monitoring et alertes**
   - Lag > X = alert
   - Trend alerting (lag augmente)

---

### Comment utiliser Processor API pour du custom processing ?

**Q:** Quand et comment utiliser la Processor API ?

**A:** La Processor API offre un contr√¥le bas niveau quand la DSL n'est pas assez flexible.

**Cas d'usage :**
- Logique complexe multi-√©tat
- Custom punctuation
- Gestion manuelle du state
- Performance critiques

**Exemple : compteur avec TTL manuel**
```java
public class CustomCounterProcessor extends AbstractProcessor<String, String> {
  private KeyValueStore<String, Long> store;
  
  @Override
  public void init(ProcessorContext context) {
    super.init(context);
    store = context.getStateStore("counter-store");
    
    // Punctuation chaque minute
    context.schedule(
      Duration.ofMinutes(1),
      WALL_CLOCK_TIME,
      timestamp -> cleanupExpired()
    );
  }
  
  @Override
  public void process(String key, String value) {
    Long count = store.get(key);
    count = (count == null) ? 1 : count + 1;
    store.put(key, count);
    context.forward(key, count);
  }
  
  private void cleanupExpired() {
    try (KeyValueIterator<String, Long> iter = store.all()) {
      while (iter.hasNext()) {
        // Logique de nettoyage
      }
    }
  }
}
```

**DSL vs Processor API :**
```
DSL : 95% des cas, recommand√©e
Processor API : 5% sp√©cifiques, quand DSL √©choue
```

---

### Comment Kafka Streams g√®re les cl√©s null ?

**Q:** Que se passe-t-il avec les messages sans cl√© ?

**A:** 

**Messages sans cl√© :**
```
null key ‚Üí partition al√©atoire
```

**Impact :**
- `groupByKey()` : non-partitionnn√©, non garantie locality
- `join()` : impossible
- `aggregate()` : sans state par cl√©

**Exemple probl√©matique :**
```java
stream.filter(...)           // key peut √™tre null
      .groupByKey()          // Undefined behavior
      .count()               // R√©sultats impr√©visibles
```

**Solution :**
```java
stream
  .selectKey((k, v) -> v.getUserId())  // Cr√©er une cl√©
  .groupByKey()
  .count()
```

**Quand accepter null :**
- Broadcasts (pas de partitionnement voulu)
- Sink sans partitionnement important

---

### Comment utiliser GlobalKTable avec de gros datasets ?

**Q:** Quand GlobalKTable devient-elle non viable ?

**A:** GlobalKTable a des limites de scalabilit√©.

**Taille acceptable :**
- < 100 MB : facile
- 100 MB - 1 GB : g√©rable
- > 1 GB : probl√©matique

**Probl√®mes avec gros datasets :**
1. **M√©moire consomm√©e :**
   - Chaque instance a une copie compl√®te
   - Multiplicit√© des instances = multiplicit√© du co√ªt

2. **Temps de chargement :**
   - D√©marrage lent
   - Rebalance long

3. **Bande passante :**
   - Chargement initial co√ªteux
   - Replication vers chaque instance

**Alternatives :**
1. **Regular KTable + co-partition**
   - Partitionn√©e
   - Pas de charge compl√®te
   - N√©cessite co-partition

2. **Redis / Cache externe**
   - Lookup par cl√© diff√©rente
   - Perte EOS
   - Latence r√©seau

3. **Diviser en sub-GlobalKTables**
   - GlobalKTable par r√©gion/segment
   - Plus complexe

**Recommandation :**
```
< 100 MB : GlobalKTable ‚úÖ
100 MB - 500 MB : KTable + co-partition
> 500 MB : Cache externe ou alternative
```

---

### Comment impl√©menter un back-pressure dans Kafka Streams ?

**Q:** Comment ralentir le processing si la destination est lente ?

**A:** Le back-pressure n'est pas natif dans Kafka Streams. Vous devez l'impl√©menter.

**Approches :**

**1. Throttling √† la source**
```java
stream.filter((k, v) -> {
  if (isDestinationSaturated()) {
    // Traiter moins de messages
    return random.nextDouble() < 0.5;  // Process 50%
  }
  return true;
});
```

**2. Retry avec d√©lai**
```java
try {
  forwardToDownstream(message);
} catch (DestinationUnavailableException e) {
  Thread.sleep(1000);
  retry();
}
```

**3. Pause du consumer**
```java
context.pause();  // Dans Processor API
Thread.sleep(5000);
context.resume();
```

**4. Queue de buffer**
```
Kafka Streams ‚Üí Buffer Local ‚Üí Destination
```

**‚ö†Ô∏è Trade-offs :**
- Back-pressure = latence
- Peut causer rebalance (timeout)
- Complexit√© accrue

**Meilleure pratique :**
```
Dimensionner correctement la destination
Monitorer le lag
Alerter plut√¥t que back-pressure
```

---

### Quels patterns √©viter en Kafka Streams ?

**Q:** Quelles erreurs courantes commettent les d√©veloppeurs ?

**A:** 

**‚ùå Anti-patterns courants :**

**1. State store sans windowing**
```java
stream.groupByKey().count()  // ‚ùå Grandit ind√©finiment
```
**‚úÖ Correction :**
```java
stream.groupByKey()
      .windowedBy(TimeWindows.ofSize(...))
      .count()
```

**2. Repartition implicite massif**
```java
stream.selectKey(...).selectKey(...).selectKey(...)  // ‚ùå Plusieurs repartitions
```
**‚úÖ Correction :**
```java
stream.selectKey((k, v) -> {
  // Calculer la cl√© finale une fois
  return finalKey(v);
})
```

**3. Side effects sans idempotence**
```java
stream.peek((k, v) -> database.insert(v))  // ‚ùå Doublon possible
```
**‚úÖ Correction :**
```java
stream.peek((k, v) -> database.upsert(v))  // Idempotent
```

**4. Oublier les exceptions**
```java
stream.map(v -> parseJson(v))  // ‚ùå NPE non g√©r√©e
```
**‚úÖ Correction :**
```java
stream.map(v -> {
  try {
    return parseJson(v);
  } catch (Exception e) {
    return null;  // ou DLT
  }
})
```

**5. Consumer group partag√©**
```java
// App 1 et App 2 : m√™me application.id
‚Üí ‚ùå Comp√©tition, pas parall√©lisation
```
**‚úÖ Correction :**
```
application.id = "app1-unique"
application.id = "app2-unique"
```

---

### Comment impl√©menter un reprocessing complet ?

**Q:** Comment rejouer tous les donn√©es depuis le d√©but ?

**A:** Le reprocessing peut √™tre n√©cessaire pour changements de logique.

**Approches :**

**1. Reset des offsets (in-place)**
```bash
kafka-streams-application-reset.sh \
  --application-id orders-stream \
  --input-topics orders \
  --bootstrap-servers localhost:9092
```
**Risques :**
- Downtime
- State corrompu possible
- R√©sultats doublons

**2. Nouveau consumer group (recommand√©)**
```
App v1 : application.id = "orders-v1"
App v2 : application.id = "orders-v2"  // Nouveau
```
- Reprocess ind√©pendant
- Pas de downtime
- Double trafic temporaire

**3. Reprocess partiel (offset sp√©cifique)**
```java
Properties props = new Properties();
props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "...");
props.put("auto.offset.reset", "earliest");  // Depuis d√©but
```

**Processus recommand√© :**
```
1. D√©ployer v2 avec nouveau application.id
2. Laisser v2 reprocess
3. Comparer outputs v1 vs v2
4. Switch downstream quand pr√™t
5. Retirer v1
```

**Timing :**
- Input topic : pas de r√©tention limite
- Changelog : peut √™tre tronqu√©
- Co√ªteux en temps et I/O

---

### Comment g√©rer les timeouts et les deadlocks ?

**Q:** Que faire quand une op√©ration prend trop longtemps ?

**A:** 

**Timeouts possibles :**

**1. Session timeout**
```
session.timeout.ms=10000
```
- Consumer se consid√®re down
- Rebalance forc√©
- Trop bas = faux rebalance

**2. Processing timeout (custom)**
```java
long start = System.currentTimeMillis();
process(message);
if (System.currentTimeMillis() - start > 5000) {
  log.error("Processing too slow!");
}
```

**3. Coordination timeout**
```
connections.max.idle.ms=...
```

**Deadlocks possibles :**

**1. Circular dependencies**
```
Stream A ‚Üí State of Stream B
Stream B ‚Üí State of Stream A
‚Üí Deadlock potentiel
```

**2. Blocking I/O dans processor**
```java
process(message) {
  database.query(...).block()  // ‚ùå Bloque le thread
}
```

**3. State store exhaustion**
```
State rempli ‚Üí RocksDB satur√© ‚Üí Stall
```

**Solutions :**
- Timeouts courts
- Non-blocking I/O
- Monitoring des threads
- Circuit breakers

---

### Comment optimiser la latence end-to-end ?

**Q:** Quels sont les bottlenecks latence ?

**A:** 

**Sources de latence :**

1. **Commit interval**
   ```
   commit.interval.ms=30000 (par d√©faut)
   ‚Üí Latence max = 30s
   ```
   **Optimisation :** r√©duire √† 5-10s

2. **Cache flushing**
   ```
   cache.max.bytes.buffering
   ‚Üí Remplissage = latence ajout√©e
   ```
   **Optimisation :** petit cache + petit commit

3. **RocksDB write**
   ```
   Async vers state store
   ‚Üí Quelques ms
   ```

4. **Network I/O**
   ```
   Production vers Kafka
   acks=all ‚Üí latence
   acks=1 ‚Üí rapide
   ```

5. **Processing logic**
   ```
   Votre code m√©tier
   ‚Üí Plus important √† optimiser
   ```

**Profiling :**
```java
long start = System.nanoTime();
process(message);
long latency = System.nanoTime() - start;

metrics.recordLatency(latency);
```

---

## R√©sum√© Rapide (Entretien)

| Concept | R√©ponse Cl√© |
|---------|-------------|
| **Kafka Streams** | Librairie de stream processing stateful |
| **KStream vs KTable** | KStream = √©v√©nements, KTable = √©tat |
| **GlobalKTable** | Petite table r√©pliqu√©e, pas de repartition |
| **Repartition** | Design de cl√© optimal d√®s la production |
| **State store** | RocksDB local + changelog Kafka |
| **TTL** | Windows ou retention explicite |
| **EOS** | Transactions Kafka + producers idempotents |
| **Windowing** | D√©coupe le temps pour agr√©gation |
| **Grace period** | Tol√®re les √©v√©nements en retard |
| **Migration** | Nouveau application.id toujours |
| **Standby replicas** | Passifs, deviennent actifs en crash |
| **GlobalKTable** | Pas de co-partition requise |
| **Task model** | Unit logique = partition set |
| **Rebalance** | Redistribution + restore |
| **TopologyTestDriver** | Test sans Kafka |
| **Dead Letter Topic** | Capture erreurs |
| **Stream-time** | Watermark implicite |
| **Processor API** | Custom bas niveau |
| **Back-pressure** | √Ä impl√©menter |
| **Anti-patterns** | State sans window, side effects |

---

**G√©n√©r√© √† partir du guide complet Kafka Streams - Niveau Senior** 
**Questions suppl√©mentaires ajout√©es pour couverture compl√®te**
